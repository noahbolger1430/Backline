python
#!/usr/bin/env python3
"""
Extract code snippets from AI conversation turn files and create repository files.
"""

import os
import re
import sys
from pathlib import Path


def extract_code_blocks(content):
    """
    Extract code blocks from the conversation content.
    Returns a list of tuples: (filepath, language, code)
    """
    code_blocks = []
    
    # Pattern to match code blocks with language specifier
    # Matches: ```language\n...code...\n```
    code_block_pattern = re.compile(r'```(\w+)\n(.*?)```', re.DOTALL)
    
    # Split content into lines for analysis
    lines = content.split('\n')
    
    i = 0
    while i < len(lines):
        line = lines[i]
        
        # Check if this line starts a code block
        match = re.match(r'^```(\w+)\s*$', line)
        if match:
            language = match.group(1)
            
            # Look backwards for the filepath (should be 1-2 lines before)
            filepath = None
            
            # Check the line immediately before the code block
            if i > 0:
                potential_path = lines[i-1].strip()
                # Check if it looks like a file path (contains . or /)
                if potential_path and not potential_path.startswith('#') and not potential_path.startswith('*'):
                    # Skip lines that are clearly not file paths
                    if '```' not in potential_path and len(potential_path) < 200:
                        # Check if it looks like a filepath
                        if '/' in potential_path or '.' in potential_path:
                            # Clean up the path - remove any markdown formatting
                            filepath = potential_path.strip('*').strip('`').strip()
            
            # Find the end of the code block
            code_lines = []
            i += 1
            while i < len(lines) and not lines[i].strip() == '```':
                code_lines.append(lines[i])
                i += 1
            
            code = '\n'.join(code_lines)
            
            # Only add if we found a filepath
            if filepath and code.strip():
                code_blocks.append((filepath, language, code))
        
        i += 1
    
    return code_blocks


def normalize_filepath(filepath):
    """
    Normalize the filepath - handle common variations.
    """
    # Remove leading/trailing whitespace
    filepath = filepath.strip()
    
    # Remove any markdown bold/italic markers
    filepath = filepath.replace('**', '').replace('__', '')
    
    # Handle __init__.py variations (sometimes written as init.py in headers)
    if filepath.endswith('/init.py') or filepath.endswith('\\init.py'):
        # Check if it should be __init__.py
        parts = filepath.rsplit('/', 1) if '/' in filepath else filepath.rsplit('\\', 1)
        if len(parts) == 2 and parts[1] == 'init.py':
            filepath = parts[0] + '/__init__.py'
    
    # Normalize path separators
    filepath = filepath.replace('\\', '/')
    
    return filepath


def create_file(repo_dir, filepath, code):
    """
    Create a file with the given code content.
    """
    full_path = repo_dir / filepath
    
    # Create parent directories if they don't exist
    full_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Write the code to the file
    with open(full_path, 'w', encoding='utf-8') as f:
        f.write(code)
        # Ensure file ends with newline
        if not code.endswith('\n'):
            f.write('\n')
    
    print(f"  Created: {filepath}")


def process_turn_file(turn_file, repo_dir):
    """
    Process a single turn file and extract code blocks.
    """
    print(f"\nProcessing: {turn_file}")
    
    try:
        with open(turn_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except UnicodeDecodeError:
        # Try with different encoding
        with open(turn_file, 'r', encoding='latin-1') as f:
            content = f.read()
    
    code_blocks = extract_code_blocks(content)
    
    if not code_blocks:
        print("  No code blocks with file paths found")
        return 0
    
    created_count = 0
    for filepath, language, code in code_blocks:
        filepath = normalize_filepath(filepath)
        
        # Skip if filepath looks invalid
        if not filepath or filepath.startswith('http') or ' ' in filepath:
            continue
            
        try:
            create_file(repo_dir, filepath, code)
            created_count += 1
        except Exception as e:
            print(f"  Error creating {filepath}: {e}")
    
    return created_count


def process_conversation_directory(conv_dir, output_base_dir):
    """
    Process all turn files in a conversation directory.
    """
    conv_dir = Path(conv_dir)
    
    if not conv_dir.exists():
        print(f"Error: Directory '{conv_dir}' does not exist")
        return
    
    # Create output directory named after the conversation directory
    repo_dir = Path(output_base_dir) / conv_dir.name
    repo_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\n{'='*60}")
    print(f"Processing conversation: {conv_dir.name}")
    print(f"Output directory: {repo_dir}")
    print(f"{'='*60}")
    
    # Find all turn files
    turn_files = []
    for f in conv_dir.iterdir():
        if f.is_file() and f.name.lower().startswith('turn') and f.suffix.lower() == '.txt':
            turn_files.append(f)
    
    if not turn_files:
        print("No turn files found (expected files named 'Turn <n>.txt')")
        return
    
    # Sort by turn number
    def get_turn_number(f):
        match = re.search(r'(\d+)', f.name)
        return int(match.group(1)) if match else 0
    
    turn_files.sort(key=get_turn_number)
    
    total_files = 0
    for turn_file in turn_files:
        total_files += process_turn_file(turn_file, repo_dir)
    
    print(f"\n{'='*60}")
    print(f"Summary: Created {total_files} files in {repo_dir}")
    print(f"{'='*60}")


def main():
    if len(sys.argv) < 2:
        print("Usage: python extract_code.py <conversation_directory> [output_directory]")
        print("")
        print("Arguments:")
        print("  conversation_directory  - Directory containing Turn <n>.txt files")
        print("  output_directory        - Where to create the repo (default: ./repos)")
        print("")
        print("Examples:")
        print("  python extract_code.py ./conversations/band-scheduler")
        print("  python extract_code.py ./conversations/band-scheduler ./output")
        print("")
        print("To process multiple conversation directories:")
        print("  python extract_code.py ./conversations/* ./output")
        sys.exit(1)
    
    # Get output directory (last argument if more than 2 args and it doesn't look like a conv dir)
    output_dir = "./repos"
    conv_dirs = sys.argv[1:]
    
    if len(sys.argv) > 2:
        # Check if last argument is an output directory (doesn't contain Turn files)
        last_arg = Path(sys.argv[-1])
        if last_arg.exists() and last_arg.is_dir():
            # Check if it has turn files
            has_turn_files = any(f.name.lower().startswith('turn') for f in last_arg.iterdir() if f.is_file())
            if not has_turn_files:
                output_dir = sys.argv[-1]
                conv_dirs = sys.argv[1:-1]
        elif not last_arg.exists():
            # Assume it's meant to be the output directory
            output_dir = sys.argv[-1]
            conv_dirs = sys.argv[1:-1]
    
    # Process each conversation directory
    for conv_dir in conv_dirs:
        conv_path = Path(conv_dir)
        if conv_path.is_dir():
            process_conversation_directory(conv_path, output_dir)
        else:
            print(f"Warning: '{conv_dir}' is not a directory, skipping")


if __name__ == "__main__":
    main()